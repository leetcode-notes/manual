

SGD 確率的勾配降下法
------------------------

https://ja.wikipedia.org/wiki/%E7%A2%BA%E7%8E%87%E7%9A%84%E5%8B%BE%E9%85%8D%E9%99%8D%E4%B8%8B%E6%B3%95

出典: フリー百科事典『ウィキペディア（Wikipedia）』
ナビゲーションに移動検索に移動

ミニバッチを使い上下に行ったり来たりしながら目的関数の値が減少していく例
確率的勾配降下法（かくりつてきこうばいこうかほう、英: stochastic gradient descent, SGD）とは、連続最適化問題に対する勾配法の乱択アルゴリズム。目的関数が、微分可能な和の形である事が必要。バッチ学習である最急降下法をオンライン学習に改良した物。




