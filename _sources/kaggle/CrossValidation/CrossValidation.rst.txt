CrossValidation
==================

Kfold, Stratified Kfold, Group Kfold
-------------------------------------------

Cross Validationの重要性

機械学習の文脈における「validation」は、一般的に「モデルの汎化性能の検証」を意味します。

汎化性能とは「未知のデータに対する性能」のことです。

validationの重要性を確認するため、「validationがない場合」を想定して、簡単な例を見てみます。

validationがない場合

パッケージやデータの準備

CrossValidation code validation_test
---------------------------------------------------------------------------

.. literalinclude:: code/validation_test.py

y_predとy_testを比較すれば良いと思うかもしれませんが、例えばKaggleではコンペ終了時までy_testの全容は分かりません。一部データはpublic LBに利用されておりスコアを確認できますが、以下の二つの問題があります。

public LBで良いスコアが出ても、一部のデータのみに過学習した結果の可能性がある
サブミットできる回数に制限がある
前者について、public LBに使われているデータはtestのデータセットの10〜30%が一般的で、仮に新しいハイパーパラメータや特徴量を使ってスコアが上がっても、一分のデータのみに効果がある「過学習」に陥っている可能性があります。

また、public LBにどのようなデータが使われているかも分かりません。極端な例ですが、二値分類の問題で0のラベルが付いたデータのみがpublic LBに使われている可能性もあります。この場合、仮にpublic LBで高いスコアを出すモデルが作成できても、そのモデルは1のラベルを当てる性能がどれだけあるか確認できていません。

後者について、Kaggleでは1日の提出回収が3〜5回とコンペごとに制限が決まっています。public LBのスコアは提出しないと分からないので、1日の提出回数分しかモデルや特徴量の試行錯誤ができない状況になってしまいます。

.. figure:: 1.png

ホールドアウト検証を実行した場合
-----------------------------------------

これらの問題に対応するのが、validationです。

validationのためのデータセットは、trainのデータセットから分割することで作成します。

.. figure:: 2.png

