.. _screiping:

screiping
=================

call ap1
+++++++++++++++++++

..   code-block:: python

     #!/usr/bin/env python55
     # -*- coding: UTF-8 -*-
     import requests
     import json

     # APIを呼び出し結果（Response)を受け取ります
     res = requests.get("http://docs.pyq.jp/_static/assets/web_api/json/data/items.json")

     # レスポンスの結果をjson形式の文字列として解析します
     items = json.loads(res.text)


     # 解析した結果（リスト）を出力します
     for item in items:
         print("{}:{}".format(item["name"], item["stock"]))


Scrapy
+++++++++++++++++++

..   code-block:: python

     scrapy startproject ensyu
     scrapy genspider ensyu docs.pyq.jp
     scrapy crawl quotes
     scrapy crawl quotes -o results/quotes.json
     scrapy crawl ensyu -o ensyu.csv


Scrapy を実運用する際に、最低限設定しておくと良い設定値について紹介します。

.. note:: DOWNLOAD_DELAY = 3

この設定は複数のURLをクロールする時に、アクセス間隔を何秒あけるかというものです。
デフォルトでは0秒になっているで、1秒以上の設定値にすると良いでしょう。詳しくは公式のドキュメントを参照してください。
