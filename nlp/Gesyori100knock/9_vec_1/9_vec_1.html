

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>第9章: ベクトル空間法 (I) &mdash; Machine-Manual-ja 17.06.Beta ドキュメント</title>
  

  
  
    <link rel="shortcut icon" href="../../../_static/showreel.ico"/>
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="索引"
              href="../../../genindex.html"/>
        <link rel="search" title="検索" href="../../../search.html"/>
    <link rel="top" title="Machine-Manual-ja 17.06.Beta ドキュメント" href="../../../index.html"/>
        <link rel="up" title="言語処理 knockout" href="../Gesyori.html"/>
        <link rel="next" title="9_vec_1 nlp100_80_1" href="code/nlp100_80_1.html"/>
        <link rel="prev" title="8_ML nlp100_79_1" href="../8_ML/code/nlp100_79_1.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> Machine-Manual-ja
          

          
          </a>

          
            
            
              <div class="version">
                17.06.Beta
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../CG/CG.html">CG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../algorithm/algorytm.html">algorytm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../framework-compare/compare.html">framework 比較</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../framework-flow/framework.html">framework workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../image/image.html">image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../kaggle/kaggle.html">kaggle</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mindmap/mindmap.html">mindmap png</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ml-scratch/ml-sctatch.html">ml scratch スクラッチでの実装</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../nlp.html">nlp 自然言語処理</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../Gesyori.html">言語処理 knockout</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../1_basic/1_basic.html">第1章: 準備運動</a></li>
<li class="toctree-l3"><a class="reference internal" href="../2_unix/2_unix.html">第2章: UNIXコマンドの基礎</a></li>
<li class="toctree-l3"><a class="reference internal" href="../3_Re/3_Re.html">第3章: 正規表現</a></li>
<li class="toctree-l3"><a class="reference internal" href="../4_morpho/4_morpho.html">第4章: 形態素解析</a></li>
<li class="toctree-l3"><a class="reference internal" href="../5_morph/5_morph.html">第5章: 係り受け解析</a></li>
<li class="toctree-l3"><a class="reference internal" href="../6_english/6_english.html">第6章: 英語テキストの処理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../7_DB/7_DB.html">第7章: データベース</a></li>
<li class="toctree-l3"><a class="reference internal" href="../8_ML/8_ML.html">第8章: 機械学習</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">第9章: ベクトル空間法 (I)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">80. コーパスの整形</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id2">81. 複合語からなる国名への対処</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id3">82. 文脈の抽出</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id4">83. 単語／文脈の頻度の計測</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id5">84. 単語文脈行列の作成</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id6">85. 主成分分析による次元圧縮</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id7">86. 単語ベクトルの表示</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8">87. 単語の類似度</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id9">88. 類似度の高い単語10件</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id10">89. 加法構成性によるアナロジー</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../9_vec_2/9_vec_2.html">第10章: ベクトル空間法 (II)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../chatbot/chatbot.html">chatbot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../install/install.html">install</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../re/re.html">文字列操作 re</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../string/string.html">string</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../python/index.html">Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../scientist_statistics/scientist.html">Data Scientist 統計学</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../web/web.html">web application framework etc</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../../index.html">Machine-Manual-ja</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../index.html">Docs</a> &raquo;</li>
      
        <li><a href="../../nlp.html">nlp 自然言語処理</a> &raquo;</li>
      
        <li><a href="../Gesyori.html">言語処理 knockout</a> &raquo;</li>
      
    <li>第9章: ベクトル空間法 (I)</li>
    <li class="wy-breadcrumbs-aside">
      
          <a href="https://github.com/nlp/Gesyori100knock/9_vec_1/9_vec_1.rst" class="fa fa-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="i">
<h1>第9章: ベクトル空間法 (I)<a class="headerlink" href="#i" title="このヘッドラインへのパーマリンク">¶</a></h1>
<p>enwiki-20150112-400-r10-105752.txt.bz2は，2015年1月12日時点の英語のWikipedia記事のうち，約400語以上で構成される記事の中から，ランダムに1/10サンプリングした105,752記事のテキストをbzip2形式で圧縮したものである．このテキストをコーパスとして，単語の意味を表すベクトル（分散表現）を学習したい．第9章の前半では，コーパスから作成した単語文脈共起行列に主成分分析を適用し，単語ベクトルを学習する過程を，いくつかの処理に分けて実装する．第9章の後半では，学習で得られた単語ベクトル（300次元）を用い，単語の類似度計算やアナロジー（類推）を行う．</p>
<p>なお，問題83を素直に実装すると，大量（約7GB）の主記憶が必要になる． メモリが不足する場合は，処理を工夫するか，1/100サンプリングのコーパスenwiki-20150112-400-r100-10576.txt.bz2を用いよ．</p>
<div class="section" id="id1">
<h2>80. コーパスの整形<a class="headerlink" href="#id1" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>文を単語列に変換する最も単純な方法は，空白文字で単語に区切ることである． ただ，この方法では文末のピリオドや括弧などの記号が単語に含まれてしまう． そこで，コーパスの各行のテキストを空白文字でトークンのリストに分割した後，各トークンに以下の処理を施し，単語から記号を除去せよ．</p>
<p>トークンの先頭と末尾に出現する次の文字を削除: .,!?;:()[]'&quot;
空文字列となったトークンは削除
以上の処理を適用した後，トークンをスペースで連結してファイルに保存せよ．</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="code/nlp100_80_1.html">9_vec_1 nlp100_80_1</a></li>
</ul>
</div>
</div>
<div class="section" id="id2">
<h2>81. 複合語からなる国名への対処<a class="headerlink" href="#id2" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>英語では，複数の語の連接が意味を成すことがある．例えば，アメリカ合衆国は&quot;United States&quot;，イギリスは&quot;United Kingdom&quot;と表現されるが，&quot;United&quot;や&quot;States&quot;，&quot;Kingdom&quot;という単語だけでは，指し示している概念・実体が曖昧である．そこで，コーパス中に含まれる複合語を認識し，複合語を1語として扱うことで，複合語の意味を推定したい．しかしながら，複合語を正確に認定するのは大変むずかしいので，ここでは複合語からなる国名を認定したい．</p>
<p>インターネット上から国名リストを各自で入手し，80のコーパス中に出現する複合語の国名に関して，スペースをアンダーバーに置換せよ．例えば，&quot;United States&quot;は&quot;United_States&quot;，&quot;Isle of Man&quot;は&quot;Isle_of_Man&quot;になるはずである．</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="code/nlp100_81_1.html">9_vec_1 nlp100_81_1</a></li>
</ul>
</div>
</div>
<div class="section" id="id3">
<h2>82. 文脈の抽出<a class="headerlink" href="#id3" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>81で作成したコーパス中に出現するすべての単語tに関して，単語tと文脈語cのペアをタブ区切り形式ですべて書き出せ．ただし，文脈語の定義は次の通りとする．</p>
<p>ある単語tの前後d単語を文脈語cとして抽出する（ただし，文脈語に単語tそのものは含まない）</p>
<p>単語tを選ぶ度に，文脈幅dは{1,2,3,4,5}の範囲でランダムに決める．</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="code/nlp100_82_1.html">9_vec_1 nlp100_82_1</a></li>
</ul>
</div>
</div>
<div class="section" id="id4">
<h2>83. 単語／文脈の頻度の計測<a class="headerlink" href="#id4" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>82の出力を利用し，以下の出現分布，および定数を求めよ．</p>
<p>f(t,c): 単語tと文脈語cの共起回数</p>
<p>f(t,∗): 単語tの出現回数</p>
<p>f(∗,c): 文脈語cの出現回数</p>
<p>N: 単語と文脈語のペアの総出現回数</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="code/nlp100_83_1.html">9_vec_1 nlp100_83_1</a></li>
</ul>
</div>
</div>
<div class="section" id="id5">
<h2>84. 単語文脈行列の作成<a class="headerlink" href="#id5" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>83の出力を利用し，単語文脈行列Xを作成せよ．ただし，行列Xの各要素Xtcは次のように定義する．</p>
<p>f(t,c)≥10ならば，Xtc=PPMI(t,c)=max{logN×f(t,c)f(t,∗)×f(∗,c),0}</p>
<p>f(t,c)&lt;10ならば，Xtc=0</p>
<p>ここで，PPMI(t,c)はPositive Pointwise Mutual Information（正の相互情報量）と呼ばれる統計量である．なお，行列Xの行数・列数は数百万オーダとなり，行列のすべての要素を主記憶上に載せることは無理なので注意すること．幸い，行列Xのほとんどの要素は0になるので，非0の要素だけを書き出せばよい．</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="code/nlp100_84_1.html">9_vec_1 nlp100_84_1</a></li>
</ul>
</div>
</div>
<div class="section" id="id6">
<h2>85. 主成分分析による次元圧縮<a class="headerlink" href="#id6" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>84で得られた単語文脈行列に対して，主成分分析を適用し，単語の意味ベクトルを300次元に圧縮せよ．</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="code/nlp100_85_1.html">9_vec_1 nlp100_85_1</a></li>
</ul>
</div>
</div>
<div class="section" id="id7">
<h2>86. 単語ベクトルの表示<a class="headerlink" href="#id7" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>85で得た単語の意味ベクトルを読み込み，&quot;United States&quot;のベクトルを表示せよ．ただし，&quot;United States&quot;は内部的には&quot;United_States&quot;と表現されていることに注意せよ．</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="code/nlp100_86_1.html">9_vec_1 nlp100_86_1</a></li>
</ul>
</div>
</div>
<div class="section" id="id8">
<h2>87. 単語の類似度<a class="headerlink" href="#id8" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>85で得た単語の意味ベクトルを読み込み，&quot;United States&quot;と&quot;U.S.&quot;のコサイン類似度を計算せよ．ただし，&quot;U.S.&quot;は内部的に&quot;U.S&quot;と表現されていることに注意せよ．</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="code/nlp100_87_1.html">9_vec_1 nlp100_87_1</a></li>
</ul>
</div>
</div>
<div class="section" id="id9">
<h2>88. 類似度の高い単語10件<a class="headerlink" href="#id9" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>85で得た単語の意味ベクトルを読み込み，&quot;England&quot;とコサイン類似度が高い10語と，その類似度を出力せよ．</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="code/nlp100_88_1.html">9_vec_1 nlp100_88_1</a></li>
</ul>
</div>
</div>
<div class="section" id="id10">
<h2>89. 加法構成性によるアナロジー<a class="headerlink" href="#id10" title="このヘッドラインへのパーマリンク">¶</a></h2>
<p>85で得た単語の意味ベクトルを読み込み，vec(&quot;Spain&quot;) - vec(&quot;Madrid&quot;) + vec(&quot;Athens&quot;)を計算し，そのベクトルと類似度の高い10語とその類似度を出力せよ．</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="code/nlp100_89_1.html">9_vec_1 nlp100_89_1</a></li>
</ul>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="code/nlp100_80_1.html" class="btn btn-neutral float-right" title="9_vec_1 nlp100_80_1" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../8_ML/code/nlp100_79_1.html" class="btn btn-neutral" title="8_ML nlp100_79_1" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2015-2019, Machine Learnning Manual.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'17.06.Beta',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../_static/language_data.js"></script>
      <script type="text/javascript" src="../../../_static/translations.js"></script>

  

  
  
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>